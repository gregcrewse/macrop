-- 11. REDSHIFT-COMPATIBLE DATASET PROFILING MACRO
{% macro profile_dataset(model_name, sample_size=10000) %}
{#
  This macro creates a comprehensive statistical profile of a dataset
  Parameters:
    - model_name: The model to profile
    - sample_size: Sample size to use for profiling (default: 10000)
#}

{% set relation = ref(model_name) %}

-- Get column information using Redshift's pg_table_def
{% set columns_query %}
  SELECT 
    column_name,
    type as data_type
  FROM pg_table_def
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ relation.schema }}'
  ORDER BY ordinal_position
{% endset %}

{% set columns_result = run_query(columns_query) %}

-- Build queries for each data type
{% set numeric_columns = [] %}
{% set string_columns = [] %}
{% set date_columns = [] %}
{% set boolean_columns = [] %}

{% if execute and columns_result and columns_result.rows %}
  {% for column in columns_result %}
    {% set col_name = column['column_name'] %}
    {% set data_type = column['data_type'] | lower %}
    
    {% if data_type in ('int', 'integer', 'bigint', 'smallint', 'numeric', 'decimal', 'float', 'double precision', 'real') %}
      {% do numeric_columns.append(col_name) %}
    {% elif data_type in ('varchar', 'char', 'text', 'character varying', 'string') %}
      {% do string_columns.append(col_name) %}
    {% elif data_type in ('date', 'datetime', 'timestamp', 'timestamp without time zone', 'timestamp with time zone') %}
      {% do date_columns.append(col_name) %}
    {% elif data_type in ('boolean', 'bool') %}
      {% do boolean_columns.append(col_name) %}
    {% endif %}
  {% endfor %}
{% endif %}

-- Get row count
{% set count_query %}
  SELECT COUNT(*) as row_count FROM {{ relation }}
{% endset %}

{% set count_result = run_query(count_query) %}
{% set row_count = count_result.columns[0][0] if count_result and count_result.rows else 0 %}

-- Calculate actual sample size
{% set actual_sample = [sample_size, row_count] | min %}

-- Create profile for numeric columns
WITH sample_data AS (
  SELECT * FROM {{ relation }}
  {% if actual_sample < row_count %}
  LIMIT {{ actual_sample }}
  {% endif %}
)

-- Numeric column profiling
{% if numeric_columns | length > 0 %}
SELECT
  'numeric' as data_type,
  column_name,
  metric,
  metric_value
FROM (
  {% for column in numeric_columns %}
  SELECT
    '{{ column }}' as column_name,
    'count' as metric,
    COUNT({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'null_count' as metric,
    (COUNT(*) - COUNT({{ column }}))::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'null_pct' as metric,
    ROUND((COUNT(*) - COUNT({{ column }})) * 100.0 / NULLIF(COUNT(*), 0), 2)::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'min' as metric,
    MIN({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'max' as metric,
    MAX({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'avg' as metric,
    AVG({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'stddev' as metric,
    STDDEV({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'p25' as metric,
    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY {{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'p50' as metric,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY {{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'p75' as metric,
    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY {{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'p95' as metric,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY {{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'distinct_values' as metric,
    COUNT(DISTINCT {{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  {% if not loop.last %}UNION ALL{% endif %}
  {% endfor %}
)

{% if string_columns | length > 0 %}
UNION ALL

-- String column profiling
SELECT
  'string' as data_type,
  column_name,
  metric,
  metric_value
FROM (
  {% for column in string_columns %}
  SELECT
    '{{ column }}' as column_name,
    'count' as metric,
    COUNT({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'null_count' as metric,
    (COUNT(*) - COUNT({{ column }}))::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'null_pct' as metric,
    ROUND((COUNT(*) - COUNT({{ column }})) * 100.0 / NULLIF(COUNT(*), 0), 2)::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'min_length' as metric,
    MIN(LENGTH({{ column }}))::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'max_length' as metric,
    MAX(LENGTH({{ column }}))::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'avg_length' as metric,
    AVG(LENGTH({{ column }}))::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'distinct_values' as metric,
    COUNT(DISTINCT {{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  {% if not loop.last %}UNION ALL{% endif %}
  {% endfor %}
)
{% endif %}

{% if date_columns | length > 0 %}
UNION ALL

-- Date column profiling
SELECT
  'date' as data_type,
  column_name,
  metric,
  metric_value
FROM (
  {% for column in date_columns %}
  SELECT
    '{{ column }}' as column_name,
    'count' as metric,
    COUNT({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'null_count' as metric,
    (COUNT(*) - COUNT({{ column }}))::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'null_pct' as metric,
    ROUND((COUNT(*) - COUNT({{ column }})) * 100.0 / NULLIF(COUNT(*), 0), 2)::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'min_date' as metric,
    MIN({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'max_date' as metric,
    MAX({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'date_range_days' as metric,
    DATEDIFF('day', MIN({{ column }}), MAX({{ column }}))::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'distinct_values' as metric,
    COUNT(DISTINCT {{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  {% if not loop.last %}UNION ALL{% endif %}
  {% endfor %}
)
{% endif %}

{% if boolean_columns | length > 0 %}
UNION ALL

-- Boolean column profiling
SELECT
  'boolean' as data_type,
  column_name,
  metric,
  metric_value
FROM (
  {% for column in boolean_columns %}
  SELECT
    '{{ column }}' as column_name,
    'count' as metric,
    COUNT({{ column }})::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'null_count' as metric,
    (COUNT(*) - COUNT({{ column }}))::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'null_pct' as metric,
    ROUND((COUNT(*) - COUNT({{ column }})) * 100.0 / NULLIF(COUNT(*), 0), 2)::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'true_count' as metric,
    SUM(CASE WHEN {{ column }} = TRUE THEN 1 ELSE 0 END)::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'true_pct' as metric,
    ROUND(SUM(CASE WHEN {{ column }} = TRUE THEN 1 ELSE 0 END) * 100.0 / NULLIF(COUNT({{ column }}), 0), 2)::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'false_count' as metric,
    SUM(CASE WHEN {{ column }} = FALSE THEN 1 ELSE 0 END)::VARCHAR as metric_value
  FROM sample_data
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'false_pct' as metric,
    ROUND(SUM(CASE WHEN {{ column }} = FALSE THEN 1 ELSE 0 END) * 100.0 / NULLIF(COUNT({{ column }}), 0), 2)::VARCHAR as metric_value
  FROM sample_data
  
  {% if not loop.last %}UNION ALL{% endif %}
  {% endfor %}
)
{% endif %}

ORDER BY data_type, column_name, metric

{% endmacro %}


-- 12. REDSHIFT-COMPATIBLE BRANCH COMPARISON MACRO
{% macro compare_branches(model_name, main_schema='main_dbt', current_schema=target.schema) %}
{#
  This macro compares a model across two branches (main and current)
  Parameters:
    - model_name: The model to compare
    - main_schema: Schema for the main branch (default: main_dbt)
    - current_schema: Schema for current branch (default: target schema)
#}

-- For Redshift, we need to check if relations exist in a compatible way
{% set current_exist_query %}
  SELECT COUNT(*) 
  FROM pg_tables
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ current_schema }}'
{% endset %}

{% set main_exist_query %}
  SELECT COUNT(*) 
  FROM pg_tables
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ main_schema }}'
{% endset %}

{% set current_exists = run_query(current_exist_query).columns[0][0] > 0 %}
{% set main_exists = run_query(main_exist_query).columns[0][0] > 0 %}

-- Check if both relations exist
{% if current_exists and main_exists %}

-- Get columns from both relations using Redshift's pg_table_def
{% set current_columns_query %}
  SELECT column_name, type as data_type
  FROM pg_table_def
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ current_schema }}'
  ORDER BY ordinal_position
{% endset %}

{% set main_columns_query %}
  SELECT column_name, type as data_type
  FROM pg_table_def
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ main_schema }}'
  ORDER BY ordinal_position
{% endset %}

{% set current_columns_result = run_query(current_columns_query) %}
{% set main_columns_result = run_query(main_columns_query) %}

-- Convert to dictionaries for easier comparison
{% set current_cols = {} %}
{% for col in current_columns_result %}
  {% do current_cols.update({col['column_name']: col['data_type']}) %}
{% endfor %}

{% set main_cols = {} %}
{% for col in main_columns_result %}
  {% do main_cols.update({col['column_name']: col['data_type']}) %}
{% endfor %}

-- Compare schema differences
{% set schema_diff = {'added': [], 'removed': [], 'type_changed': []} %}

{% for col_name, data_type in current_cols.items() %}
  {% if col_name not in main_cols %}
    {% do schema_diff['added'].append(col_name) %}
  {% elif data_type != main_cols[col_name] %}
    {% do schema_diff['type_changed'].append({'name': col_name, 'main_type': main_cols[col_name], 'current_type': data_type}) %}
  {% endif %}
{% endfor %}

{% for col_name, data_type in main_cols.items() %}
  {% if col_name not in current_cols %}
    {% do schema_diff['removed'].append(col_name) %}
  {% endif %}
{% endfor %}

-- Get common columns for data comparison
{% set common_columns = [] %}
{% for col_name in current_cols.keys() %}
  {% if col_name in main_cols and current_cols[col_name] == main_cols[col_name] %}
    {% do common_columns.append(col_name) %}
  {% endif %}
{% endfor %}

-- Get row counts for both relations - use fully qualified names for Redshift
{% set current_count_query %}
  SELECT COUNT(*) FROM "{{ current_schema }}"."{{ model_name }}"
{% endset %}

{% set main_count_query %}
  SELECT COUNT(*) FROM "{{ main_schema }}"."{{ model_name }}"
{% endset %}

{% set current_count_result = run_query(current_count_query) %}
{% set main_count_result = run_query(main_count_query) %}

{% set current_count = current_count_result.columns[0][0] if current_count_result and current_count_result.rows else 0 %}
{% set main_count = main_count_result.columns[0][0] if main_count_result and main_count_result.rows else 0 %}

-- Data comparison query for common columns using Redshift syntax
WITH main_data AS (
  SELECT
    {% for col in common_columns %}
    {{ col }}{% if not loop.last %},{% endif %}
    {% endfor %}
  FROM "{{ main_schema }}"."{{ model_name }}"
),

current_data AS (
  SELECT
    {% for col in common_columns %}
    {{ col }}{% if not loop.last %},{% endif %}
    {% endfor %}
  FROM "{{ current_schema }}"."{{ model_name }}"
),

in_main_not_current AS (
  SELECT 
    {% for col in common_columns %}
    {{ col }}{% if not loop.last %},{% endif %}
    {% endfor %}
  FROM main_data
  EXCEPT
  SELECT 
    {% for col in common_columns %}
    {{ col }}{% if not loop.last %},{% endif %}
    {% endfor %}
  FROM current_data
),

in_current_not_main AS (
  SELECT 
    {% for col in common_columns %}
    {{ col }}{% if not loop.last %},{% endif %}
    {% endfor %}
  FROM current_data
  EXCEPT
  SELECT 
    {% for col in common_columns %}
    {{ col }}{% if not loop.last %},{% endif %}
    {% endfor %}
  FROM main_data
),

summary AS (
  SELECT
    '{{ model_name }}' as model_name,
    '{{ main_schema }}' as main_schema,
    '{{ current_schema }}' as current_schema,
    {{ main_count }} as main_row_count,
    {{ current_count }} as current_row_count,
    (SELECT COUNT(*) FROM in_main_not_current) as rows_in_main_not_current,
    (SELECT COUNT(*) FROM in_current_not_main) as rows_in_current_not_main
)

SELECT * FROM summary

{% else %}
  {% if execute %}
    {% if not current_exists %}
      {{ log('WARNING: ' ~ model_name ~ ' does not exist in current schema: ' ~ current_schema, info=True) }}
    {% endif %}
    {% if not main_exists %}
      {{ log('WARNING: ' ~ model_name ~ ' does not exist in main schema: ' ~ main_schema, info=True) }}
    {% endif %}
  {% endif %}

  -- Return placeholder result if either relation does not exist
  SELECT
    '{{ model_name }}' as model_name,
    '{{ main_schema }}' as main_schema,
    '{{ current_schema }}' as current_schema,
    {% if main_exists %}{{ main_count }}{% else %}NULL{% endif %} as main_row_count,
    {% if current_exists %}{{ current_count }}{% else %}NULL{% endif %} as current_row_count,
    NULL as rows_in_main_not_current,
    NULL as rows_in_current_not_main
{% endif %}

{% endmacro %}


-- 13. REDSHIFT-COMPATIBLE DOWNSTREAM IMPACT ANALYZER
{% macro analyze_downstream_impact(model_name, max_depth=3) %}
{#
  This macro analyzes the impact of changes to a model on downstream models
  Parameters:
    - model_name: The model to analyze impact for
    - max_depth: Maximum depth of downstream dependencies to analyze
#}

-- For Redshift, use the dbt_dependencies table if available
{% set downstream_query %}
  WITH RECURSIVE model_deps AS (
    -- Base case: the starting model
    SELECT 
      node_id AS unique_id,
      model_name AS name,
      0 as depth
    FROM {{ ref('dbt_models') }}
    WHERE model_name = '{{ model_name }}'
    
    UNION ALL
    
    -- Recursive case: downstream dependencies
    SELECT
      downstream.node_id AS unique_id,
      downstream.model_name AS name,
      m.depth + 1 as depth
    FROM model_deps m
    JOIN {{ ref('dbt_dependencies') }} deps ON deps.upstream_id = m.unique_id
    JOIN {{ ref('dbt_models') }} downstream ON downstream.node_id = deps.downstream_id
    WHERE m.depth < {{ max_depth }}
  )
  
  SELECT DISTINCT
    name,
    depth
  FROM model_deps
  WHERE depth > 0  -- Skip the starting model
  ORDER BY depth, name
{% endset %}

{% set downstream_models_result = run_query(downstream_query) %}

{% if execute %}
  {{ log('Downstream impact analysis for model "' ~ model_name ~ '":', info=True) }}
  
  {% if downstream_models_result and downstream_models_result.rows %}
    {% set levels = {} %}
    
    -- Group models by depth level
    {% for model in downstream_models_result %}
      {% set model_name = model['name'] %}
      {% set depth = model['depth'] %}
      
      {% if depth not in levels %}
        {% do levels.update({depth: []}) %}
      {% endif %}
      
      {% do levels[depth].append(model_name) %}
    {% endfor %}
    
    -- Display models grouped by level
    {% for level, models in levels.items() %}
      {{ log('Level ' ~ level ~ ' (' ~ models|length ~ ' models):', info=True) }}
      {% for model in models %}
        {{ log('  - ' ~ model, info=True) }}
      {% endfor %}
    {% endfor %}
    
    {{ log('', info=True) }}
    {{ log('Total downstream models affected: ' ~ downstream_models_result|length, info=True) }}
  {% else %}
    {{ log('No downstream models found or dependency data not available.', info=True) }}
    {{ log('Make sure you have dbt_models and dbt_dependencies seed files.', info=True) }}
  {% endif %}
{% endif %}

{% endmacro %}


-- 14. REDSHIFT-COMPATIBLE DATA DRIFT DETECTOR
{% macro detect_data_drift(model_name, time_column, time_window='1 month', compare_window='1 month') %}
{#
  This macro detects data drift in a model over time
  Parameters:
    - model_name: The model to analyze
    - time_column: The column containing timestamps
    - time_window: The window for recent data (default: 1 month)
    - compare_window: The window for comparison data (default: 1 month)
#}

{% set relation = ref(model_name) %}

-- Get numerical columns using Redshift's pg_table_def
{% set numeric_columns_query %}
  SELECT column_name 
  FROM pg_table_def
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ relation.schema }}'
  AND type IN ('int', 'integer', 'bigint', 'smallint', 'numeric', 'decimal', 'double precision', 'real')
  AND column_name != '{{ time_column }}'
  ORDER BY ordinal_position
{% endset %}

{% set categorical_columns_query %}
  SELECT column_name 
  FROM pg_table_def
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ relation.schema }}'
  AND type IN ('varchar', 'char', 'text', 'character varying')
  AND column_name != '{{ time_column }}'
  ORDER BY ordinal_position
{% endset %}

{% set numeric_columns_result = run_query(numeric_columns_query) %}
{% set categorical_columns_result = run_query(categorical_columns_query) %}

{% set numeric_columns = numeric_columns_result.columns[0].values() if numeric_columns_result and numeric_columns_result.rows else [] %}
{% set categorical_columns = categorical_columns_result.columns[0].values() if categorical_columns_result and categorical_columns_result.rows else [] %}

-- Parse time windows to Redshift syntax
{% set time_window_unit = time_window.split(' ')[1] | lower %}
{% set time_window_value = time_window.split(' ')[0] | int %}
{% set compare_window_unit = compare_window.split(' ')[1] | lower %}
{% set compare_window_value = compare_window.split(' ')[0] | int %}

-- Numerical drift analysis
WITH recent_data AS (
  SELECT *
  FROM {{ relation }}
  WHERE {{ time_column }} >= DATEADD({{ time_window_unit }}, -{{ time_window_value }}, CURRENT_DATE)
),

comparison_data AS (
  SELECT *
  FROM {{ relation }}
  WHERE {{ time_column }} >= DATEADD({{ time_window_unit }}, -{{ time_window_value }}, DATEADD({{ compare_window_unit }}, -{{ compare_window_value }}, CURRENT_DATE))
    AND {{ time_column }} < DATEADD({{ time_window_unit }}, -{{ time_window_value }}, CURRENT_DATE)
),

numeric_drift AS (
  {% for column in numeric_columns %}
  SELECT
    '{{ column }}' as column_name,
    'numeric' as data_type,
    'avg' as metric,
    ROUND(recent.avg_value, 2) as recent_value,
    ROUND(comparison.avg_value, 2) as comparison_value,
    ROUND(ABS(recent.avg_value - comparison.avg_value) / NULLIF(comparison.avg_value, 0) * 100, 2) as pct_change
  FROM (
    SELECT AVG({{ column }}) as avg_value
    FROM recent_data
  ) recent,
  (
    SELECT AVG({{ column }}) as avg_value
    FROM comparison_data
  ) comparison
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'numeric' as data_type,
    'stddev' as metric,
    ROUND(recent.stddev_value, 2) as recent_value,
    ROUND(comparison.stddev_value, 2) as comparison_value,
    ROUND(ABS(recent.stddev_value - comparison.stddev_value) / NULLIF(comparison.stddev_value, 0) * 100, 2) as pct_change
  FROM (
    SELECT STDDEV({{ column }}) as stddev_value
    FROM recent_data
  ) recent,
  (
    SELECT STDDEV({{ column }}) as stddev_value
    FROM comparison_data
  ) comparison
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'numeric' as data_type,
    'null_rate' as metric,
    ROUND(recent.null_rate * 100, 2) as recent_value,
    ROUND(comparison.null_rate * 100, 2) as comparison_value,
    ABS(recent.null_rate - comparison.null_rate) * 100 as pct_change
  FROM (
    SELECT (COUNT(*) - COUNT({{ column }})) / NULLIF(COUNT(*), 0) as null_rate
    FROM recent_data
  ) recent,
  (
    SELECT (COUNT(*) - COUNT({{ column }})) / NULLIF(COUNT(*), 0) as null_rate
    FROM comparison_data
  ) comparison
  
  {% if not loop.last %}UNION ALL{% endif %}
  {% endfor %}
),

-- Categorical drift analysis
categorical_drift AS (
  {% for column in categorical_columns %}
  SELECT
    '{{ column }}' as column_name,
    'categorical' as data_type,
    'distinct_count' as metric,
    recent.distinct_count as recent_value,
    comparison.distinct_count as comparison_value,
    ROUND(ABS(recent.distinct_count - comparison.distinct_count) / NULLIF(comparison.distinct_count, 0) * 100, 2) as pct_change
  FROM (
    SELECT COUNT(DISTINCT {{ column }}) as distinct_count
    FROM recent_data
  ) recent,
  (
    SELECT COUNT(DISTINCT {{ column }}) as distinct_count
    FROM comparison_data
  ) comparison
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'categorical' as data_type,
    'null_rate' as metric,
    ROUND(recent.null_rate * 100, 2) as recent_value,
    ROUND(comparison.null_rate * 100, 2) as comparison_value,
    ABS(recent.null_rate - comparison.null_rate) * 100 as pct_change
  FROM (
    SELECT (COUNT(*) - COUNT({{ column }})) / NULLIF(COUNT(*), 0) as null_rate
    FROM recent_data
  ) recent,
  (
    SELECT (COUNT(*) - COUNT({{ column }})) / NULLIF(COUNT(*), 0) as null_rate
    FROM comparison_data
  ) comparison
  
  UNION ALL
  
  SELECT
    '{{ column }}' as column_name,
    'categorical' as data_type,
    'top_category_change' as metric,
    recent.top_category as recent_value,
    comparison.top_category as comparison_value,
    CASE WHEN recent.top_category = comparison.top_category THEN 0 ELSE 1 END * 100 as pct_change
  FROM (
    SELECT {{ column }} as top_category
    FROM recent_data
    WHERE {{ column }} IS NOT NULL
    GROUP BY {{ column }}
    ORDER BY COUNT(*) DESC
    LIMIT 1
  ) recent,
  (
    SELECT {{ column }} as top_category
    FROM comparison_data
    WHERE {{ column }} IS NOT NULL
    GROUP BY {{ column }}
    ORDER BY COUNT(*) DESC
    LIMIT 1
  ) comparison
  
  {% if not loop.last %}UNION ALL{% endif %}
  {% endfor %}
),

-- Combined results with significance flagging
combined_results AS (
  SELECT 
    column_name,
    data_type,
    metric,
    recent_value,
    comparison_value,
    pct_change,
    CASE 
      WHEN pct_change > 50 THEN 'High'
      WHEN pct_change > 20 THEN 'Medium'
      WHEN pct_change > 5 THEN 'Low'
      ELSE 'Normal'
    END as drift_severity
  FROM (
    {% if numeric_columns|length > 0 %}
    SELECT * FROM numeric_drift
    {% endif %}
    
    {% if numeric_columns|length > 0 and categorical_columns|length > 0 %}
    UNION ALL
    {% endif %}
    
    {% if categorical_columns|length > 0 %}
    SELECT * FROM categorical_drift
    {% endif %}
  )
)

SELECT * FROM combined_results
WHERE drift_severity != 'Normal'
ORDER BY 
  CASE 
    WHEN drift_severity = 'High' THEN 1
    WHEN drift_severity = 'Medium' THEN 2
    WHEN drift_severity = 'Low' THEN 3
    ELSE 4
  END,
  pct_change DESC

{% endmacro %}


-- 15. REDSHIFT-COMPATIBLE A/B MODEL TESTING
{% macro ab_test_models(model_a, model_b, metrics=['row_count', 'data_quality']) %}
{#
  This macro performs A/B testing between two model variants
  Parameters:
    - model_a: First model variant
    - model_b: Second model variant
    - metrics: Metrics to compare
#}

{% set relation_a = ref(model_a) %}
{% set relation_b = ref(model_b) %}

-- 1. Row count comparison
{% if 'row_count' in metrics %}
  {% set count_a_query %}
    SELECT COUNT(*) FROM {{ relation_a }}
  {% endset %}
  
  {% set count_b_query %}
    SELECT COUNT(*) FROM {{ relation_b }}
  {% endset %}
  
  {% set count_a_result = run_query(count_a_query) %}
  {% set count_b_result = run_query(count_b_query) %}
  
  {% set count_a = count_a_result.columns[0][0] if count_a_result and count_a_result.rows else 0 %}
  {% set count_b = count_b_result.columns[0][0] if count_b_result and count_b_result.rows else 0 %}
  
  WITH row_count_comparison AS (
    SELECT
      '{{ model_a }}' as model_a,
      '{{ model_b }}' as model_b,
      {{ count_a }} as model_a_rows,
      {{ count_b }} as model_b_rows,
      {{ count_b }} - {{ count_a }} as row_diff,
      ROUND(({{ count_b }} - {{ count_a }}) * 100.0 / NULLIF({{ count_a }}, 0), 2) as pct_diff
  )
  
  SELECT * FROM row_count_comparison
{% endif %}

-- 2. Data quality comparison
{% if 'data_quality' in metrics %}
  -- Get common columns between the two models using Redshift pg_table_def
  {% set columns_a_query %}
    SELECT column_name, type as data_type
    FROM pg_table_def
    WHERE tablename = '{{ model_a }}'
    AND schemaname = '{{ relation_a.schema }}'
  {% endset %}
  
  {% set columns_b_query %}
    SELECT column_name, type as data_type
    FROM pg_table_def
    WHERE tablename = '{{ model_b }}'
    AND schemaname = '{{ relation_b.schema }}'
  {% endset %}
  
  {% set columns_a_result = run_query(columns_a_query) %}
  {% set columns_b_result = run_query(columns_b_query) %}
  
  -- Convert to dictionaries
  {% set cols_a = {} %}
  {% if columns_a_result and columns_a_result.rows %}
    {% for col in columns_a_result %}
      {% do cols_a.update({col['column_name']: col['data_type']}) %}
    {% endfor %}
  {% endif %}
  
  {% set cols_b = {} %}
  {% if columns_b_result and columns_b_result.rows %}
    {% for col in columns_b_result %}
      {% do cols_b.update({col['column_name']: col['data_type']}) %}
    {% endfor %}
  {% endif %}
  
  -- Find common columns with matching types
  {% set common_columns = [] %}
  {% for col, type in cols_a.items() %}
    {% if col in cols_b and cols_b[col] == type %}
      {% do common_columns.append(col) %}
    {% endif %}
  {% endfor %}
  
  -- For each common column, compare null counts and distinct values
  {% for column in common_columns %}
    {% set null_a_query %}
      SELECT 
        SUM(CASE WHEN {{ column }} IS NULL THEN 1 ELSE 0 END) as null_count,
        COUNT(DISTINCT {{ column }}) as distinct_count
      FROM {{ relation_a }}
    {% endset %}
    
    {% set null_b_query %}
      SELECT 
        SUM(CASE WHEN {{ column }} IS NULL THEN 1 ELSE 0 END) as null_count,
        COUNT(DISTINCT {{ column }}) as distinct_count
      FROM {{ relation_b }}
    {% endset %}
    
    {% set null_a_result = run_query(null_a_query) %}
    {% set null_b_result = run_query(null_b_query) %}
    
    {% if execute and null_a_result and null_a_result.rows and null_b_result and null_b_result.rows %}
      {{ log('Data quality comparison for column ' ~ column ~ ':', info=True) }}
      {{ log('  - ' ~ model_a ~ ': ' ~ null_a_result.columns[0][0] ~ ' nulls, ' ~ null_a_result.columns[1][0] ~ ' distinct values', info=True) }}
      {{ log('  - ' ~ model_b ~ ': ' ~ null_b_result.columns[0][0] ~ ' nulls, ' ~ null_b_result.columns[1][0] ~ ' distinct values', info=True) }}
    {% endif %}
    
    WITH a_stats AS (
      SELECT
        '{{ column }}' as column_name,
        {{ null_a_result.columns[0][0] }} as null_count_a,
        {{ null_a_result.columns[1][0] }} as distinct_count_a
    ),
    
    b_stats AS (
      SELECT
        '{{ column }}' as column_name,
        {{ null_b_result.columns[0][0] }} as null_count_b,
        {{ null_b_result.columns[1][0] }} as distinct_count_b
    ),
    
    comparison AS (
      SELECT
        a_stats.column_name,
        null_count_a,
        null_count_b,
        null_count_b - null_count_a as null_diff,
        distinct_count_a,
        distinct_count_b,
        distinct_count_b - distinct_count_a as distinct_diff
      FROM a_stats, b_stats
      WHERE a_stats.column_name = b_stats.column_name
    )
    
    SELECT * FROM comparison
    
    {% if not loop.last %}UNION ALL{% endif %}
  {% endfor %}
{% endif %}

{% endmacro %}-- 1. REDSHIFT-COMPATIBLE DATA COMPARISON MACRO
{% macro compare_model_versions(old_model_name, new_model_name, key_column, columns_to_compare=none) %}
{# 
  This macro compares data between an old and new version of a model
  Parameters:
    - old_model_name: The name of the original model
    - new_model_name: The name of the new/updated model
    - key_column: The primary key or unique identifier column
    - columns_to_compare: Optional list of specific columns to compare (defaults to all)
#}

{% set old_relation = ref(old_model_name) %}
{% set new_relation = ref(new_model_name) %}

{% if columns_to_compare is none %}
  -- Get columns directly from the database using Redshift-friendly approach
  {% set old_columns_query %}
    SELECT column_name
    FROM pg_table_def
    WHERE tablename = '{{ old_model_name }}' 
    AND schemaname = '{{ old_relation.schema }}'
    ORDER BY ordinal_position
  {% endset %}
  
  {% set old_columns_result = run_query(old_columns_query) %}
  {% if execute and old_columns_result and old_columns_result.rows %}
    {% set old_columns = old_columns_result.columns[0].values() %}
    {% set columns_to_compare = old_columns %}
  {% else %}
    -- Fallback to a few basic columns if metadata query fails
    {% set columns_to_compare = [key_column] %}
    {{ log("WARNING: Could not fetch columns for model " ~ old_model_name ~ ". Using key column only.", info=true) }}
  {% endif %}
{% endif %}

WITH old_data AS (
  SELECT 
    {{ key_column }},
    {% for column in columns_to_compare %}
      {{ column }}{% if not loop.last %},{% endif %}
    {% endfor %}
  FROM {{ old_relation }}
),

new_data AS (
  SELECT 
    {{ key_column }},
    {% for column in columns_to_compare %}
      {{ column }}{% if not loop.last %},{% endif %}
    {% endfor %}
  FROM {{ new_relation }}
),

comparison AS (
  SELECT
    COALESCE(source_model.{{ key_column }}, target_model.{{ key_column }}) AS {{ key_column }},
    {% for column in columns_to_compare %}
      {% if column != key_column %}
        CASE
          WHEN source_model.{{ column }} = target_model.{{ column }} THEN 'SAME'
          WHEN source_model.{{ column }} IS NULL AND target_model.{{ column }} IS NULL THEN 'SAME'
          WHEN source_model.{{ column }} IS NULL THEN 'NULL→VALUE'
          WHEN target_model.{{ column }} IS NULL THEN 'VALUE→NULL'
          ELSE 'DIFFERENT'
        END AS {{ column }}_comparison{% if not loop.last %},{% endif %}
      {% endif %}
    {% endfor %}
  FROM old_data AS source_model
  FULL OUTER JOIN new_data AS target_model
  ON source_model.{{ key_column }} = target_model.{{ key_column }}
),

summary AS (
  SELECT
    '{{ old_model_name }} vs {{ new_model_name }}' AS comparison_name,
    {% for column in columns_to_compare %}
      {% if column != key_column %}
        SUM(CASE WHEN {{ column }}_comparison = 'SAME' THEN 1 ELSE 0 END) AS {{ column }}_same_count,
        SUM(CASE WHEN {{ column }}_comparison = 'DIFFERENT' THEN 1 ELSE 0 END) AS {{ column }}_diff_count,
        SUM(CASE WHEN {{ column }}_comparison = 'NULL→VALUE' THEN 1 ELSE 0 END) AS {{ column }}_null_to_value_count,
        SUM(CASE WHEN {{ column }}_comparison = 'VALUE→NULL' THEN 1 ELSE 0 END) AS {{ column }}_value_to_null_count{% if not loop.last %},{% endif %}
      {% endif %}
    {% endfor %}
  FROM comparison
)

SELECT * FROM summary

{% endmacro %}


-- 2. REDSHIFT-COMPATIBLE DATA SUMMARY MACRO
{% macro summarize_model(model_name, group_by_columns=none, numeric_columns=none) %}
{#
  This macro generates summary statistics for a given model
  Parameters:
    - model_name: The name of the model to summarize
    - group_by_columns: Optional list of columns to group by
    - numeric_columns: Optional list of numeric columns to summarize
#}

{% set relation = ref(model_name) %}

{% if numeric_columns is none %}
  {% set numeric_columns_query %}
    SELECT column_name 
    FROM pg_table_def
    WHERE tablename = '{{ model_name }}'
    AND schemaname = '{{ relation.schema }}'
    AND type IN ('int', 'integer', 'bigint', 'smallint', 'numeric', 'decimal', 'double precision', 'real')
    ORDER BY ordinal_position
  {% endset %}
  
  {% set numeric_columns_result = run_query(numeric_columns_query) %}
  {% if execute and numeric_columns_result and numeric_columns_result.rows %}
    {% set numeric_columns = numeric_columns_result.columns[0].values() %}
  {% else %}
    {% set numeric_columns = [] %}
    {{ log("WARNING: Could not fetch numeric columns for model " ~ model_name ~ ".", info=true) }}
  {% endif %}
{% endif %}

{% if group_by_columns is none %}
  -- Global summary without grouping
  SELECT
    '{{ model_name }}' AS model_name,
    COUNT(*) AS total_rows,
    {% for column in numeric_columns %}
      MIN({{ column }}) AS {{ column }}_min,
      MAX({{ column }}) AS {{ column }}_max,
      AVG({{ column }}) AS {{ column }}_avg,
      PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY {{ column }}) AS {{ column }}_median,
      COUNT({{ column }}) AS {{ column }}_count,
      COUNT(*) - COUNT({{ column }}) AS {{ column }}_null_count,
      (COUNT(*) - COUNT({{ column }})) * 100.0 / NULLIF(COUNT(*), 0) AS {{ column }}_null_percentage
      {% if not loop.last %},{% endif %}
    {% endfor %}
  FROM {{ relation }}
{% else %}
  -- Grouped summary
  SELECT
    {% for column in group_by_columns %}
      {{ column }},
    {% endfor %}
    COUNT(*) AS total_rows,
    {% for column in numeric_columns %}
      {% if column not in group_by_columns %}
        MIN({{ column }}) AS {{ column }}_min,
        MAX({{ column }}) AS {{ column }}_max,
        AVG({{ column }}) AS {{ column }}_avg,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY {{ column }}) AS {{ column }}_median,
        COUNT({{ column }}) AS {{ column }}_count,
        COUNT(*) - COUNT({{ column }}) AS {{ column }}_null_count,
        (COUNT(*) - COUNT({{ column }})) * 100.0 / NULLIF(COUNT(*), 0) AS {{ column }}_null_percentage
        {% if not loop.last %},{% endif %}
      {% endif %}
    {% endfor %}
  FROM {{ relation }}
  GROUP BY
    {% for column in group_by_columns %}
      {{ column }}{% if not loop.last %},{% endif %}
    {% endfor %}
{% endif %}

{% endmacro %}


-- 3. REDSHIFT-COMPATIBLE MODEL REFERENCE DISCOVERY AND UPDATE
{% macro find_model_references(old_model_name) %}
{#
  This macro finds all references to a given model in your project
  Parameters:
    - old_model_name: The name of the model to find references for
#}

-- For Redshift, this is best done by scanning files outside the database
-- This is a simplified version that logs direct references

{% set project_files_query %}
  SELECT f.path
  FROM (
    SELECT path
    FROM {{ ref('dbt_project_files') }}
    WHERE path LIKE '%.sql'
  ) AS f
{% endset %}

{% set project_files_result = run_query(project_files_query) %}
{% set results = [] %}
{% if execute and project_files_result and project_files_result.rows %}
  {% set project_files = project_files_result.columns[0].values() %}
  
  {% for file_path in project_files %}
    {% set file_content_query %}
      SELECT file_content 
      FROM {{ ref('dbt_file_contents') }}
      WHERE file_path = '{{ file_path }}'
    {% endset %}
    
    {% set file_content_result = run_query(file_content_query) %}
    {% if file_content_result and file_content_result.rows %}
      {% set file_content = file_content_result.columns[0][0] %}
      
      {% if file_content and file_content is string and file_content | lower is contains('ref(\'' ~ old_model_name ~ '\')') or file_content | lower is contains('ref("' ~ old_model_name ~ '")') %}
        {% do results.append(file_path) %}
      {% endif %}
    {% endif %}
  {% endfor %}
  
  {{ log('Found references to model "' ~ old_model_name ~ '" in the following files:', info=True) }}
  {% for file in results %}
    {{ log('  - ' ~ file, info=True) }}
  {% endfor %}
{% else %}
  {{ log('WARNING: Could not find project files. Make sure you have a dbt_project_files seed file.', info=True) }}
  {{ log('To find model references, you may need to use a shell script or Python script instead.', info=True) }}
{% endif %}

{% endmacro %}


-- 4. REDSHIFT-COMPATIBLE MODEL CHANGE TESTING MACRO
{% macro test_model_change(old_model_name, new_model_name, config_options={}) %}
{#
  This macro creates a test to verify a new model against an old one
  Parameters:
    - old_model_name: The name of the original model
    - new_model_name: The name of the new/updated model
    - config_options: Optional configuration options for the test
#}

{{ config(options=config_options) }}

-- Count checks
WITH old_model_count AS (
  SELECT COUNT(*) AS row_count FROM {{ ref(old_model_name) }}
),

new_model_count AS (
  SELECT COUNT(*) AS row_count FROM {{ ref(new_model_name) }}
),

count_check AS (
  SELECT 
    old_model_count.row_count AS old_row_count,
    new_model_count.row_count AS new_row_count,
    ABS(new_model_count.row_count - old_model_count.row_count) AS row_count_diff,
    CASE 
      WHEN old_model_count.row_count = 0 THEN NULL
      ELSE ABS(new_model_count.row_count - old_model_count.row_count) / NULLIF(old_model_count.row_count, 0)
    END AS row_count_pct_change
  FROM old_model_count, new_model_count
),

-- Fail the test if count change exceeds threshold
test_result AS (
  SELECT
    CASE 
      WHEN row_count_pct_change > 0.1 THEN 'FAIL: Row count changed by more than 10%'
      ELSE 'PASS'
    END AS status,
    old_row_count,
    new_row_count,
    row_count_diff,
    row_count_pct_change
  FROM count_check
  WHERE status = 'FAIL: Row count changed by more than 10%'
)

SELECT * FROM test_result

{% endmacro %}


-- 5. REDSHIFT-COMPATIBLE COLUMN LINEAGE TRACKER
{% macro trace_column_lineage(model_name, column_name) %}
{#
  This macro traces the lineage of a specific column through upstream models
  Parameters:
    - model_name: The model containing the column
    - column_name: The column to trace
#}

-- For Redshift, this needs to use dbt's graph objects rather than information_schema
{% set model_refs_query %}
  WITH RECURSIVE model_lineage AS (
    -- Base case: the starting model
    SELECT 
      node_id AS unique_id,
      model_name AS name,
      NULL AS referenced_by,
      0 AS depth
    FROM {{ ref('dbt_models') }}
    WHERE model_name = '{{ model_name }}'
    
    UNION ALL
    
    -- Recursive case: all upstream models
    SELECT
      upstream.node_id AS unique_id,
      upstream.model_name AS name,
      ml.name AS referenced_by,
      ml.depth + 1 AS depth
    FROM model_lineage ml
    JOIN {{ ref('dbt_dependencies') }} deps ON deps.downstream_id = ml.unique_id
    JOIN {{ ref('dbt_models') }} upstream ON upstream.node_id = deps.upstream_id
  )
  
  SELECT
    unique_id,
    name,
    referenced_by,
    depth
  FROM model_lineage
  ORDER BY depth ASC, name
{% endset %}

{% set model_refs_result = run_query(model_refs_query) %}

{% if execute and model_refs_result and model_refs_result.rows %}
  {{ log('Tracing lineage for column "' ~ column_name ~ '" in model "' ~ model_name ~ '":', info=True) }}
  
  {% for model_ref in model_refs_result %}
    {% set current_model = model_ref['name'] %}
    {% set depth = model_ref['depth'] %}
    {% set referenced_by = model_ref['referenced_by'] %}
    
    {% set model_sql_query %}
      SELECT model_sql 
      FROM {{ ref('dbt_models') }}
      WHERE model_name = '{{ current_model }}'
    {% endset %}
    
    {% set model_sql_result = run_query(model_sql_query) %}
    
    {% if model_sql_result and model_sql_result.rows %}
      {% set model_sql = model_sql_result.columns[0][0] %}
      
      {% if model_sql and model_sql is string %}
        {% set indentation = '  ' * depth %}
        {% if column_name | lower in model_sql | lower %}
          {{ log(indentation ~ '- ' ~ current_model ~ (referenced_by is not none and ' (referenced by ' ~ referenced_by ~ ')' or ''), info=True) }}
          
          -- Extract column references in SELECT statements
          {% set select_pattern = r'SELECT.*?FROM'|regex_search(model_sql, ignorecase=True) %}
          {% if select_pattern %}
            {% set select_clause = select_pattern[0] %}
            {% if column_name | lower in select_clause | lower %}
              -- Found the column in SELECT clause, look for its definition
              {{ log(indentation ~ '  Column "' ~ column_name ~ '" found in SELECT clause', info=True) }}
            {% endif %}
          {% endif %}
        {% endif %}
      {% endif %}
    {% endif %}
  {% endfor %}
{% else %}
  {{ log('WARNING: Could not find model lineage data. Make sure you have dbt_models and dbt_dependencies seed files.', info=True) }}
{% endif %}

{% endmacro %}


-- 6. REDSHIFT-COMPATIBLE MODEL DEPENDENCY VISUALIZER
{% macro visualize_model_dependencies(model_name, max_depth=3) %}
{#
  This macro generates a Mermaid diagram of model dependencies
  Parameters:
    - model_name: The model to visualize dependencies for
    - max_depth: Maximum depth of upstream dependencies to show
#}

{% set dependencies_query %}
  WITH RECURSIVE model_deps AS (
    -- Base case: the starting model
    SELECT 
      node_id AS unique_id,
      model_name AS name,
      'model' AS resource_type,
      0 AS depth
    FROM {{ ref('dbt_models') }}
    WHERE model_name = '{{ model_name }}'
    
    UNION ALL
    
    -- Recursive case: upstream dependencies
    SELECT
      upstream.node_id AS unique_id,
      upstream.model_name AS name,
      'model' AS resource_type,
      d.depth + 1 AS depth
    FROM model_deps d
    JOIN {{ ref('dbt_dependencies') }} deps ON deps.downstream_id = d.unique_id
    JOIN {{ ref('dbt_models') }} upstream ON upstream.node_id = deps.upstream_id
    WHERE d.depth < {{ max_depth }}
  )
  
  SELECT DISTINCT
    unique_id,
    name,
    resource_type,
    depth
  FROM model_deps
  ORDER BY depth ASC, name
{% endset %}

{% set dependencies_result = run_query(dependencies_query) %}

{% set edges_query %}
  WITH model_deps AS (
    SELECT 
      node_id AS unique_id,
      model_name AS name
    FROM {{ ref('dbt_models') }}
    WHERE model_name IN (
      SELECT name FROM ({{ dependencies_query }})
    )
  )
  
  SELECT DISTINCT
    source_model.name AS source_name,
    target_model.name AS target_name
  FROM {{ ref('dbt_dependencies') }} deps
  JOIN model_deps source_model ON source_model.unique_id = deps.upstream_id
  JOIN model_deps target_model ON target_model.unique_id = deps.downstream_id
  ORDER BY source_name, target_name
{% endset %}

{% set edges_result = run_query(edges_query) %}

{% if execute and dependencies_result and dependencies_result.rows %}
  {{ log('graph TD', info=True) }}
  
  -- Define nodes with styling
  {% for dep in dependencies_result %}
    {% set node_name = dep['name'] %}
    {% set resource_type = dep['resource_type'] %}
    {% set depth = dep['depth'] %}
    
    {% set node_style = '' %}
    {% if node_name == model_name %}
      {% set node_style = ':::focus' %}
    {% elif resource_type == 'model' %}
      {% set node_style = ':::model' %}
    {% elif resource_type == 'source' %}
      {% set node_style = ':::source' %}
    {% elif resource_type == 'seed' %}
      {% set node_style = ':::seed' %}
    {% endif %}
    
    {{ log('  ' ~ node_name ~ node_style, info=True) }}
  {% endfor %}
  
  -- Define edges
  {% if edges_result and edges_result.rows %}
    {% for edge in edges_result %}
      {{ log('  ' ~ edge['source_name'] ~ ' --> ' ~ edge['target_name'], info=True) }}
    {% endfor %}
  {% endif %}
  
  -- Define styles
  {{ log('  classDef focus fill:#f96,stroke:#333,stroke-width:2px;', info=True) }}
  {{ log('  classDef model fill:#bbf,stroke:#33f,stroke-width:1px;', info=True) }}
  {{ log('  classDef source fill:#bfb,stroke:#3f3,stroke-width:1px;', info=True) }}
  {{ log('  classDef seed fill:#fbf,stroke:#f3f,stroke-width:1px;', info=True) }}
{% else %}
  {{ log('WARNING: Could not find model dependency data. Make sure you have dbt_models and dbt_dependencies seed files.', info=True) }}
{% endif %}

{% endmacro %}


-- 7. REDSHIFT-COMPATIBLE DATA QUALITY MONITORING MACRO
{% macro monitor_data_quality(model_name, tests_to_run=['not_null', 'unique', 'relationships'], columns=none) %}
{#
  This macro generates data quality tests for specified columns
  Parameters:
    - model_name: The model to generate tests for
    - tests_to_run: List of test types to generate
    - columns: Optional list of columns to test (defaults to all)
#}

{% set relation = ref(model_name) %}

{% if columns is none %}
  {% set columns_query %}
    SELECT column_name
    FROM pg_table_def
    WHERE tablename = '{{ model_name }}'
    AND schemaname = '{{ relation.schema }}'
    ORDER BY ordinal_position
  {% endset %}
  
  {% set columns_result = run_query(columns_query) %}
  {% if execute and columns_result and columns_result.rows %}
    {% set columns = columns_result.columns[0].values() %}
  {% else %}
    {% set columns = [] %}
    {{ log("WARNING: Could not fetch columns for model " ~ model_name ~ ".", info=true) }}
  {% endif %}
{% endif %}

{% if execute %}
  {{ log('# Data Quality Tests for model: ' ~ model_name, info=True) }}
  
  {% for column in columns %}
    {{ log('version: 2', info=True) }}
    {{ log('', info=True) }}
    {{ log('models:', info=True) }}
    {{ log('  - name: ' ~ model_name, info=True) }}
    {{ log('    columns:', info=True) }}
    {{ log('      - name: ' ~ column, info=True) }}
    {{ log('        tests:', info=True) }}
    
    {% if 'not_null' in tests_to_run %}
      {{ log('          - not_null', info=True) }}
    {% endif %}
    
    {% if 'unique' in tests_to_run and loop.index == 1 %}
      -- Assume first column might be a primary key
      {{ log('          - unique', info=True) }}
    {% endif %}
    
    {% if 'relationships' in tests_to_run and column | lower is containing('_id') %}
      -- For columns that look like foreign keys
      {{ log('          - relationships:', info=True) }}
      {{ log('              to: ref(\'' ~ column | replace('_id', '') ~ '\')', info=True) }}
      {{ log('              field: id', info=True) }}
    {% endif %}
    
    {% if 'accepted_values' in tests_to_run %}
      -- Get possible values for the column (limited to prevent huge lists)
      {% set values_query %}
        SELECT DISTINCT {{ column }}
        FROM {{ relation }}
        WHERE {{ column }} IS NOT NULL
        LIMIT 10
      {% endset %}
      
      {% set values_result = run_query(values_query) %}
      {% if values_result and values_result.rows and values_result.rows | length > 0 and values_result.rows | length < 10 %}
        {% set values = values_result.columns[0].values() %}
        {{ log('          - accepted_values:', info=True) }}
        {{ log('              values: [' ~ values|join(', ') ~ ']', info=True) }}
      {% endif %}
    {% endif %}
    
    {{ log('', info=True) }}
  {% endfor %}
{% endif %}

{% endmacro %}


-- 8. REDSHIFT-COMPATIBLE INCREMENTAL TESTING MACRO
{% macro test_incremental_load(model_name, date_column, lookback_days=7) %}
{#
  This macro tests incremental loading for a model
  Parameters:
    - model_name: The model to test incremental loading for
    - date_column: The column used for incremental filtering
    - lookback_days: Number of days to test
#}

-- Get the max date in the model
{% set max_date_query %}
  SELECT MAX({{ date_column }}) as max_date
  FROM {{ ref(model_name) }}
{% endset %}

{% set max_date_result = run_query(max_date_query) %}
{% if execute and max_date_result and max_date_result.rows %}
  {% set max_date = max_date_result.columns[0][0] %}

  -- Create a CTE for each day in the lookback period
  WITH 
  {% for i in range(lookback_days) %}
    day_{{ i }} AS (
      SELECT 
        '{{ model_name }}' as model_name,
        DATEADD(day, -{{ i }}, '{{ max_date }}') as load_date,
        COUNT(*) as record_count
      FROM {{ ref(model_name) }}
      WHERE {{ date_column }} <= DATEADD(day, -{{ i }}, '{{ max_date }}')
    ){% if not loop.last %},{% endif %}
  {% endfor %}

  -- Union all day CTEs
  SELECT * FROM 
  {% for i in range(lookback_days) %}
    day_{{ i }}{% if not loop.last %} UNION ALL {% endif %}
  {% endfor %}
  ORDER BY load_date DESC
{% else %}
  -- Return a placeholder result if unable to get max date
  SELECT
    '{{ model_name }}' as model_name,
    CURRENT_DATE as load_date,
    0 as record_count
{% endif %}

{% endmacro %}


-- 9. REDSHIFT-COMPATIBLE SCHEMA CHANGE DETECTOR
{% macro detect_schema_changes(model_name, compare_env='prod') %}
{#
  This macro detects schema changes between environments
  Parameters:
    - model_name: The model to check for schema changes
    - compare_env: The environment to compare with (default: prod)
#}

-- Get current environment schema
{% set current_schema_query %}
  SELECT 
    column_name,
    type as data_type,
    character_maximum_length,
    CASE WHEN is_nullable = 'YES' THEN TRUE ELSE FALSE END as is_nullable
  FROM pg_table_def
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ target.schema }}'
  ORDER BY ordinal_position
{% endset %}

{% set current_schema_result = run_query(current_schema_query) %}

-- Get comparison environment schema reference
{% set prod_schema_query %}
  SELECT 
    column_name,
    type as data_type,
    character_maximum_length,
    CASE WHEN is_nullable = 'YES' THEN TRUE ELSE FALSE END as is_nullable
  FROM pg_table_def
  WHERE tablename = '{{ model_name }}'
  AND schemaname = '{{ env_var(compare_env ~ "_schema", compare_env) }}'
  ORDER BY ordinal_position
{% endset %}

{% if execute %}
  -- Try to run the comparison query, but it might fail if env doesn't exist
  {% try %}
    {% set prod_schema_result = run_query(prod_schema_query) %}
    
    {% if current_schema_result and current_schema_result.rows and prod_schema_result and prod_schema_result.rows %}
      -- Convert result sets to dictionaries for comparison
      {% set current_columns = {} %}
      {% for row in current_schema_result %}
        {% do current_columns.update({row['column_name']: {
          'data_type': row['data_type'],
          'character_maximum_length': row['character_maximum_length'],
          'is_nullable': row['is_nullable']
        }}) %}
      {% endfor %}
      
      {% set prod_columns = {} %}
      {% for row in prod_schema_result %}
        {% do prod_columns.update({row['column_name']: {
          'data_type': row['data_type'],
          'character_maximum_length': row['character_maximum_length'],
          'is_nullable': row['is_nullable']
        }}) %}
      {% endfor %}
      
      -- Find columns in current but not in prod (added)
      {% set added_columns = [] %}
      {% for col in current_columns.keys() %}
        {% if col not in prod_columns %}
          {% do added_columns.append(col) %}
        {% endif %}
      {% endfor %}
      
      -- Find columns in prod but not in current (removed)
      {% set removed_columns = [] %}
      {% for col in prod_columns.keys() %}
        {% if col not in current_columns %}
          {% do removed_columns.append(col) %}
        {% endif %}
      {% endfor %}
      
      -- Find columns with type changes
      {% set changed_columns = [] %}
      {% for col in current_columns.keys() %}
        {% if col in prod_columns %}
          {% set current = current_columns[col] %}
          {% set prod = prod_columns[col] %}
          {% if current.data_type != prod.data_type or 
                current.character_maximum_length != prod.character_maximum_length or
                current.is_nullable != prod.is_nullable %}
            {% do changed_columns.append({
              'name': col,
              'current_type': current.data_type,
              'prod_type': prod.data_type,
              'current_length': current.character_maximum_length,
              'prod_length': prod.character_maximum_length,
              'current_nullable': current.is_nullable,
              'prod_nullable': prod.is_nullable
            }) %}
          {% endif %}
        {% endif %}
      {% endfor %}
      
      -- Log the results
      {{ log('Schema change detection for model "' ~ model_name ~ '" comparing with ' ~ compare_env ~ ':', info=True) }}
      
      {% if added_columns %}
        {{ log('Added columns:', info=True) }}
        {% for col in added_columns %}
          {{ log('  - ' ~ col ~ ' (' ~ current_columns[col].data_type ~ ')', info=True) }}
        {% endfor %}
      {% else %}
        {{ log('No columns added.', info=True) }}
      {% endif %}
      
      {% if removed_columns %}
        {{ log('Removed columns:', info=True) }}
        {% for col in removed_columns %}
          {{ log('  - ' ~ col ~ ' (' ~ prod_columns[col].data_type ~ ')', info=True) }}
        {% endfor %}
      {% else %}
        {{ log('No columns removed.', info=True) }}
      {% endif %}
      
      {% if changed_columns %}
        {{ log('Changed columns:', info=True) }}
        {% for col in changed_columns %}
          {% set changes = [] %}
          {% if col.current_type != col.prod_type %}
            {% do changes.append('type: ' ~ col.prod_type ~ ' → ' ~ col.current_type) %}
          {% endif %}
          {% if col.current_length != col.prod_length %}
            {% do changes.append('length: ' ~ col.prod_length ~ ' → ' ~ col.current_length) %}
          {% endif %}
          {% if col.current_nullable != col.prod_nullable %}
            {% do changes.append('nullable: ' ~ col.prod_nullable ~ ' → ' ~ col.current_nullable) %}
          {% endif %}
          {{ log('  - ' ~ col.name ~ ' (' ~ changes|join(', ') ~ ')', info=True) }}
        {% endfor %}
      {% else %}
        {{ log('No columns changed.', info=True) }}
      {% endif %}
    {% else %}
      {{ log('WARNING: Could not fetch schema information from one or both environments.', info=True) }}
    {% endif %}
  {% endtry %}
{% endif %}

{% endmacro %}


-- 10. REDSHIFT-COMPATIBLE MODEL CONSOLIDATION VERIFICATION MACRO
{% macro verify_model_consolidation(source_models, target_model, key_columns=none, comparison_type='full') %}
{#
  This macro verifies that a consolidation of multiple models into one target model
  retains all necessary data from the source models.
  
  Parameters:
    - source_models: List of models being consolidated or migrated from
    - target_model: The new or updated model receiving the consolidated data
    - key_columns: List of columns to use as join keys (if null, will attempt to find common keys)
    - comparison_type: Type of comparison to perform ('full', 'union', 'rows', 'schema')
#}

-- Check parameter validity
{% if source_models is string %}
  {% set source_models = [source_models] %}
{% endif %}

{% if execute %}
  {{ log('Verifying model consolidation from ' ~ source_models|join(', ') ~ ' to ' ~ target_model, info=True) }}
  {{ log('', info=True) }}
{% endif %}

-- Get the target model relation
{% set target_relation = ref(target_model) %}

-- Get target model columns using Redshift's pg_table_def
{% set target_columns_query %}
  SELECT 
    column_name,
    type as data_type,
    CASE WHEN is_nullable = 'YES' THEN TRUE ELSE FALSE END as is_nullable
  FROM pg_table_def
  WHERE tablename = '{{ target_model }}'
  AND schemaname = '{{ target_relation.schema }}'
  ORDER BY ordinal_position
{% endset %}

{% set target_columns_result = run_query(target_columns_query) %}

-- Store target model columns in a dictionary for easy lookup
{% set target_cols = {} %}
{% if execute and target_columns_result and target_columns_result.rows %}
  {% for col in target_columns_result %}
    {% do target_cols.update({col['column_name']: {
      'data_type': col['data_type'],
      'is_nullable': col['is_nullable']
    }}) %}
  {% endfor %}
{% endif %}

-- Get target row count
{% set target_count_query %}
  SELECT COUNT(*) FROM {{ target_relation }}
{% endset %}

{% set target_count_result = run_query(target_count_query) %}
{% set target_count = target_count_result.columns[0][0] if target_count_result and target_count_result.rows else 0 %}

-- Store source model info
{% set source_models_info = [] %}

-- Process each source model
{% for source_model in source_models %}
  {% set source_relation = ref(source_model) %}
  
  -- Get source model columns
  {% set source_columns_query %}
    SELECT 
      column_name,
      type as data_type,
      CASE WHEN is_nullable = 'YES' THEN TRUE ELSE FALSE END as is_nullable
    FROM pg_table_def
    WHERE tablename = '{{ source_model }}'
    AND schemaname = '{{ source_relation.schema }}'
    ORDER BY ordinal_position
  {% endset %}
  
  {% set source_columns_result = run_query(source_columns_query) %}
  
  -- Store source columns in a dictionary
  {% set source_cols = {} %}
  {% if execute and source_columns_result and source_columns_result.rows %}
    {% for col in source_columns_result %}
      {% do source_cols.update({col['column_name']: {
        'data_type': col['data_type'],
        'is_nullable': col['is_nullable']
      }}) %}
    {% endfor %}
  {% endif %}
  
  -- Get source row count
  {% set source_count_query %}
    SELECT COUNT(*) FROM {{ source_relation }}
  {% endset %}
  
  {% set source_count_result = run_query(source_count_query) %}
  {% set source_count = source_count_result.columns[0][0] if source_count_result and source_count_result.rows else 0 %}
  
  -- Find common columns between source and target
  {% set common_columns = [] %}
  {% for col_name in source_cols %}
    {% if col_name in target_cols %}
      {% do common_columns.append(col_name) %}
    {% endif %}
  {% endfor %}
  
  -- Find columns that exist in source but not in target (potentially missing data)
  {% set missing_columns = [] %}
  {% for col_name in source_cols %}
    {% if col_name not in target_cols %}
      {% do missing_columns.append(col_name) %}
    {% endif %}
  {% endfor %}
  
  -- Store source model info
  {% do source_models_info.append({
    'name': source_model,
    'columns': source_cols,
    'common_columns': common_columns,
    'missing_columns': missing_columns,
    'row_count': source_count
  }) %}
  
  {% if execute %}
    {{ log('Source model: ' ~ source_model, info=True) }}
    {{ log('- Row count: ' ~ source_count, info=True) }}
    {{ log('- Columns: ' ~ source_cols|length, info=True) }}
    {{ log('- Common columns with target: ' ~ common_columns|length, info=True) }}
    
    {% if missing_columns %}
      {{ log('- WARNING: Columns missing from target model:', info=True) }}
      {% for col in missing_columns %}
        {{ log('  - ' ~ col, info=True) }}
      {% endfor %}
    {% endif %}
    
    {{ log('', info=True) }}
  {% endif %}
{% endfor %}

-- Calculate total row count from all source models
{% set total_source_rows = 0 %}
{% for model_info in source_models_info %}
  {% set total_source_rows = total_source_rows + model_info.row_count %}
{% endfor %}

{% if execute %}
  {{ log('Target model: ' ~ target_model, info=True) }}
  {{ log('- Row count: ' ~ target_count, info=True) }}
  {{ log('- Columns: ' ~ target_cols|length, info=True) }}
  {{ log('- Total source rows: ' ~ total_source_rows, info=True) }}
  {{ log('- Row count difference: ' ~ (target_count - total_source_rows), info=True) }}
  {{ log('', info=True) }}
{% endif %}

-- Determine key columns if not provided
{% if key_columns is none %}
  {% set possible_keys = ['id', 'key', 'pk', 'primary_key'] %}
  {% set source_model_common_columns = [] %}
  
  -- Get common columns from all source models
  {% if source_models_info|length > 0 %}
    {% set source_model_common_columns = source_models_info[0].common_columns %}
    
    {% for model_info in source_models_info %}
      {% if loop.index > 1 %}
        {% set temp_common = [] %}
        {% for col in source_model_common_columns %}
          {% if col in model_info.common_columns %}
            {% do temp_common.append(col) %}
          {% endif %}
        {% endfor %}
        {% set source_model_common_columns = temp_common %}
      {% endif %}
    {% endfor %}
  {% endif %}
  
  -- Attempt to find key columns
  {% set found_keys = [] %}
  {% for col in source_model_common_columns %}
    {% for key_pattern in possible_keys %}
      {% if col|lower is containing(key_pattern) %}
        {% do found_keys.append(col) %}
      {% endif %}
    {% endfor %}
  {% endfor %}
  
  {% if found_keys|length > 0 %}
    {% set key_columns = found_keys %}
  {% elif source_model_common_columns|length > 0 %}
    {% set key_columns = [source_model_common_columns[0]] %}
  {% else %}
    {% set key_columns = [] %}
  {% endif %}
{% endif %}

{% if execute %}
  {{ log('Using key columns for comparison: ' ~ key_columns|join(', '), info=True) }}
  {{ log('', info=True) }}
{% endif %}

-- Perform detailed comparison based on comparison type
{% if comparison_type == 'full' or comparison_type == 'rows' %}
  -- For each source model, check if all its rows are represented in the target model
  {% for model_info in source_models_info %}
    {% set source_model = model_info.name %}
    {% set source_relation = ref(source_model) %}
    
    -- Create a query that finds rows in source not in target
    {% if key_columns|length > 0 %}
      {% set missing_rows_query %}
        WITH source_data AS (
          SELECT 
            {% for key_col in key_columns %}
            {{ key_col }}{% if not loop.last %},{% endif %}
            {% endfor %}
          FROM {{ source_relation }}
        ),
        
        target_data AS (
          SELECT 
            {% for key_col in key_columns %}
            {{ key_col }}{% if not loop.last %},{% endif %}
            {% endfor %}
          FROM {{ target_relation }}
        ),
        
        missing_rows AS (
          SELECT s.*
          FROM source_data s
          LEFT JOIN target_data t ON 
            {% for key_col in key_columns %}
            s.{{ key_col }} = t.{{ key_col }}{% if not loop.last %} AND {% endif %}
            {% endfor %}
          WHERE 
            {% for key_col in key_columns %}
            t.{{ key_col }} IS NULL{% if not loop.last %} OR {% endif %}
            {% endfor %}
        )
        
        SELECT COUNT(*) as missing_row_count FROM missing_rows
      {% endset %}
      
      {% set missing_rows_result = run_query(missing_rows_query) %}
      {% set missing_rows = missing_rows_result.columns[0][0] if missing_rows_result and missing_rows_result.rows else 0 %}
      
      {% if execute %}
        {% if missing_rows > 0 %}
          {{ log('WARNING: Found ' ~ missing_rows ~ ' rows in ' ~ source_model ~ ' that are not in ' ~ target_model ~ ' based on key columns', info=True) }}
          
          -- Get sample of missing rows for debugging
          {% set sample_query %}
            WITH source_data AS (
              SELECT *
              FROM {{ source_relation }}
            ),
            
            target_data AS (
              SELECT 
                {% for key_col in key_columns %}
                {{ key_col }}{% if not loop.last %},{% endif %}
                {% endfor %}
              FROM {{ target_relation }}
            ),
            
            missing_rows AS (
              SELECT s.*
              FROM source_data s
              LEFT JOIN target_data t ON 
                {% for key_col in key_columns %}
                s.{{ key_col }} = t.{{ key_col }}{% if not loop.last %} AND {% endif %}
                {% endfor %}
              WHERE 
                {% for key_col in key_columns %}
                t.{{ key_col }} IS NULL{% if not loop.last %} OR {% endif %}
                {% endfor %}
            )
            
            SELECT * FROM missing_rows
            LIMIT 5
          {% endset %}
          
          {% set sample_rows_result = run_query(sample_query) %}
          
          {{ log('Sample of missing rows:', info=True) }}
          {% if sample_rows_result and sample_rows_result.rows %}
            {% for i in range(sample_rows_result.rows|length) %}
              {% set row_values = [] %}
              {% for col_name in sample_rows_result.column_names %}
                {% do row_values.append(col_name ~ ': ' ~ sample_rows_result.rows[i][loop.index0]) %}
              {% endfor %}
              {{ log('  - {' ~ row_values|join(', ') ~ '}', info=True) }}
            {% endfor %}
          {% endif %}
        {% else %}
          {{ log('✓ All rows from ' ~ source_model ~ ' are represented in ' ~ target_model ~ ' based on key columns', info=True) }}
        {% endif %}
        
        {{ log('', info=True) }}
      {% endif %}
    {% else %}
      {{ log('WARNING: Unable to compare rows between ' ~ source_model ~ ' and ' ~ target_model ~ ' without key columns', info=True) }}
      {{ log('', info=True) }}
    {% endif %}
  {% endfor %}
{% endif %}

{% if comparison_type == 'full' or comparison_type == 'union' %}
  -- Check if the target model contains at least the union of all values from source models
  {% if key_columns|length > 0 %}
    {% set union_query %}
      WITH all_source_keys AS (
        {% for model_info in source_models_info %}
          SELECT 
            {% for key_col in key_columns %}
            {{ key_col }}{% if not loop.last %},{% endif %}
            {% endfor %}
          FROM {{ ref(model_info.name) }}
          
          {% if not loop.last %}UNION{% endif %}
        {% endfor %}
      ),
      
      target_keys AS (
        SELECT 
          {% for key_col in key_columns %}
          {{ key_col }}{% if not loop.last %},{% endif %}
          {% endfor %}
        FROM {{ target_relation }}
      ),
      
      missing_keys AS (
        SELECT s.*
        FROM all_source_keys s
        LEFT JOIN target_keys t ON 
          {% for key_col in key_columns %}
          s.{{ key_col }} = t.{{ key_col }}{% if not loop.last %} AND {% endif %}
          {% endfor %}
        WHERE 
          {% for key_col in key_columns %}
          t.{{ key_col }} IS NULL{% if not loop.last %} OR {% endif %}
          {% endfor %}
      )
      
      SELECT COUNT(*) as missing_union_count FROM missing_keys
    {% endset %}
    
    {% set missing_union_result = run_query(union_query) %}
    {% set missing_union = missing_union_result.columns[0][0] if missing_union_result and missing_union_result.rows else 0 %}
    
    {% if execute %}
      {% if missing_union > 0 %}
        {{ log('WARNING: Found ' ~ missing_union ~ ' unique key combinations from all source models that are missing in the target model', info=True) }}
        
        -- Get sample of missing union rows
        {% set sample_union_query %}
          WITH all_source_keys AS (
            {% for model_info in source_models_info %}
              SELECT 
                {% for key_col in key_columns %}
                {{ key_col }}{% if not loop.last %},{% endif %}
                {% endfor %}
              FROM {{ ref(model_info.name) }}
              
              {% if not loop.last %}UNION{% endif %}
            {% endfor %}
          ),
          
          target_keys AS (
            SELECT 
              {% for key_col in key_columns %}
              {{ key_col }}{% if not loop.last %},{% endif %}
              {% endfor %}
            FROM {{ target_relation }}
          ),
          
          missing_keys AS (
            SELECT s.*
            FROM all_source_keys s
            LEFT JOIN target_keys t ON 
              {% for key_col in key_columns %}
              s.{{ key_col }} = t.{{ key_col }}{% if not loop.last %} AND {% endif %}
              {% endfor %}
            WHERE 
              {% for key_col in key_columns %}
              t.{{ key_col }} IS NULL{% if not loop.last %} OR {% endif %}
              {% endfor %}
          )
          
          SELECT * FROM missing_keys
          LIMIT 5
        {% endset %}
        
        {% set sample_union_result = run_query(sample_union_query) %}
        
        {{ log('Sample of missing union keys:', info=True) }}
        {% if sample_union_result and sample_union_result.rows %}
          {% for i in range(sample_union_result.rows|length) %}
            {% set row_values = [] %}
            {% for col_name in sample_union_result.column_names %}
              {% do row_values.append(col_name ~ ': ' ~ sample_union_result.rows[i][loop.index0]) %}
            {% endfor %}
            {{ log('  - {' ~ row_values|join(', ') ~ '}', info=True) }}
          {% endfor %}
        {% endif %}
      {% else %}
        {{ log('✓ The target model contains all unique key combinations from all source models', info=True) }}
      {% endif %}
      
      {{ log('', info=True) }}
    {% endif %}
  {% endif %}
{% endif %}

{% if comparison_type == 'full' or comparison_type == 'schema' %}
  -- Check for any critical columns that might be missing in the target
  {% set all_source_columns = {} %}
  
  -- Gather all unique columns from all source models
  {% for model_info in source_models_info %}
    {% for col_name, col_info in model_info.columns.items() %}
      {% if col_name not in all_source_columns %}
        {% do all_source_columns.update({col_name: col_info}) %}
      {% endif %}
    {% endfor %}
  {% endfor %}
  
  -- Check for columns missing in target
  {% set critical_missing_columns = [] %}
  {% for col_name, col_info in all_source_columns.items() %}
    {% if col_name not in target_cols and col_name not in key_columns %}
      {% do critical_missing_columns.append(col_name) %}
    {% endif %}
  {% endfor %}
  
  {% if execute %}
    {% if critical_missing_columns %}
      {{ log('WARNING: The following columns from source models are missing in the target model:', info=True) }}
      {% for col in critical_missing_columns %}
        {{ log('  - ' ~ col, info=True) }}
      {% endfor %}
    {% else %}
      {{ log('✓ All critical source columns are represented in the target model', info=True) }}
    {% endif %}
    
    {{ log('', info=True) }}
  {% endif %}
{% endif %}

-- Return a summary table with results
WITH source_summary AS (
  {% for model_info in source_models_info %}
    SELECT
      '{{ model_info.name }}' as model_name,
      '{{ source_models | join(",") }}' as source_models,
      '{{ target_model }}' as target_model,
      {{ model_info.row_count }} as row_count,
      {{ model_info.columns | length }} as column_count,
      {{ model_info.common_columns | length }} as common_columns,
      {{ model_info.missing_columns | length }} as missing_columns
    {% if not loop.last %}UNION ALL{% endif %}
  {% endfor %}
),

target_summary AS (
  SELECT
    '{{ target_model }}' as model_name,
    '{{ source_models | join(",") }}' as source_models,
    '{{ target_model }}' as target_model,
    {{ target_count }} as row_count,
    {{ target_cols | length }} as column_count,
    NULL as common_columns,
    NULL as missing_columns
),

combined_summary AS (
  SELECT * FROM source_summary
  UNION ALL
  SELECT * FROM target_summary
)

SELECT * FROM combined_summary

{% endmacro %}
